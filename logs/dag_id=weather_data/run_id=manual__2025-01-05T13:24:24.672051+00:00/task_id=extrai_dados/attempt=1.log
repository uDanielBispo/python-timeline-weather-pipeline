[2025-01-05 10:24:34,884] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: weather_data.extrai_dados manual__2025-01-05T13:24:24.672051+00:00 [queued]>
[2025-01-05 10:24:34,899] {taskinstance.py:1159} INFO - Dependencies all met for <TaskInstance: weather_data.extrai_dados manual__2025-01-05T13:24:24.672051+00:00 [queued]>
[2025-01-05 10:24:34,899] {taskinstance.py:1356} INFO - 
--------------------------------------------------------------------------------
[2025-01-05 10:24:34,899] {taskinstance.py:1357} INFO - Starting attempt 1 of 1
[2025-01-05 10:24:34,899] {taskinstance.py:1358} INFO - 
--------------------------------------------------------------------------------
[2025-01-05 10:24:34,936] {taskinstance.py:1377} INFO - Executing <Task(PythonOperator): extrai_dados> on 2025-01-05 13:24:24.672051+00:00
[2025-01-05 10:24:34,946] {standard_task_runner.py:52} INFO - Started process 13546 to run task
[2025-01-05 10:24:34,978] {standard_task_runner.py:79} INFO - Running: ['airflow', 'tasks', 'run', 'weather_data', 'extrai_dados', 'manual__2025-01-05T13:24:24.672051+00:00', '--job-id', '50', '--raw', '--subdir', 'DAGS_FOLDER/weather_data.py', '--cfg-path', '/tmp/tmpfqfroqyi', '--error-file', '/tmp/tmpmlrdggg5']
[2025-01-05 10:24:34,979] {standard_task_runner.py:80} INFO - Job 50: Subtask extrai_dados
[2025-01-05 10:24:35,091] {task_command.py:370} INFO - Running <TaskInstance: weather_data.extrai_dados manual__2025-01-05T13:24:24.672051+00:00 [running]> on host daniel-virtual-machine
[2025-01-05 10:24:35,198] {taskinstance.py:1569} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=airflow
AIRFLOW_CTX_DAG_ID=weather_data
AIRFLOW_CTX_TASK_ID=extrai_dados
AIRFLOW_CTX_EXECUTION_DATE=2025-01-05T13:24:24.672051+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2025-01-05T13:24:24.672051+00:00
[2025-01-05 10:24:35,202] {taskinstance.py:1889} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/daniel/Documents/Alura/python_apache_airflow_pipeline/venv/lib/python3.9/site-packages/airflow/operators/python.py", line 171, in execute
    return_value = self.execute_callable()
  File "/home/daniel/Documents/Alura/python_apache_airflow_pipeline/venv/lib/python3.9/site-packages/airflow/operators/python.py", line 189, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/home/daniel/Documents/Alura/python_apache_airflow_pipeline/dags/weather_data.py", line 29, in extract_data
    date_end = ds_add(data_interval_end, 7)
  File "/home/daniel/Documents/Alura/python_apache_airflow_pipeline/venv/lib/python3.9/site-packages/airflow/macros/__init__.py", line 44, in ds_add
    dt = datetime.strptime(str(ds), "%Y-%m-%d") + timedelta(days=days)
  File "/usr/lib/python3.9/_strptime.py", line 568, in _strptime_datetime
    tt, fraction, gmtoff_fraction = _strptime(data_string, format)
  File "/usr/lib/python3.9/_strptime.py", line 349, in _strptime
    raise ValueError("time data %r does not match format %r" %
ValueError: time data 'data_interval_end.strftime("%Y-%m-%d")' does not match format '%Y-%m-%d'
[2025-01-05 10:24:35,220] {taskinstance.py:1395} INFO - Marking task as FAILED. dag_id=weather_data, task_id=extrai_dados, execution_date=20250105T132424, start_date=20250105T132434, end_date=20250105T132435
[2025-01-05 10:24:35,239] {standard_task_runner.py:92} ERROR - Failed to execute job 50 for task extrai_dados (time data 'data_interval_end.strftime("%Y-%m-%d")' does not match format '%Y-%m-%d'; 13546)
[2025-01-05 10:24:35,271] {local_task_job.py:156} INFO - Task exited with return code 1
[2025-01-05 10:24:35,318] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
